
#include "stdafx.h"
#ifndef SHARED_HANDLERS
#include "201711296.h"
#endif
#ifdef _DEBUG
#define new DEBUG_NEW
#endif
#include "201711296Doc.h"
#include "201711296View.h"
#include <Windows.h>
#include <set>
#include <algorithm>
#include <string>
#include <vector>
#include <iterator>




std::vector<std::vector<cv::Point> > contours;
std::vector<Point2f> approx;
bool t1 = false, t2 = false, t3 = false, t4 = false, t5 = false;

void CMy201711296View::On3ss()
{
	cv::Mat srcimg = cv::imread("captureimg.jpg");
	int srcimgy = 140;
	int srcterm = 1;
	CFileDialog dlg(TRUE, ".avi", NULL, NULL, "AVI File (*.avi)|*.avi||");
	if (IDOK != dlg.DoModal())
		return;
	CString cfilename = dlg.GetPathName();
	CT2CA strAtl(cfilename);

	int range_count = 0;

	Scalar red(0, 0, 255);
	Scalar blue(255, 0, 0);
	Scalar yellow(0, 255, 255);
	Scalar magenta(255, 0, 255);


	Mat rgb_color = Mat(1, 1, CV_8UC3, red);
	Mat hsv_color;

	cvtColor(rgb_color, hsv_color, COLOR_BGR2HSV);

	int hue = 15;

	int low_hue = hue - 10;
	int high_hue = hue + 10;

	int low_hue1 = 0, low_hue2 = 0;
	int high_hue1 = 0, high_hue2 = 0;

	if (low_hue < 10) {
		range_count = 2;
		high_hue1 = 180;
		low_hue1 = low_hue + 180;
		high_hue2 = high_hue;
		low_hue2 = 0;
	}
	else if (high_hue > 170) {
		range_count = 2;
		high_hue1 = low_hue;
		low_hue1 = 180;
		high_hue2 = high_hue - 180;
		low_hue2 = 0;
	}
	else {
		range_count = 1;

		low_hue1 = low_hue;
		high_hue1 = high_hue;
	}


	VideoCapture cap;
	String filename(strAtl);
	cap.open(filename);
	Mat img_frame, img_hsv;

	if (!cap.isOpened()) {
		std::cerr << "ERROR! Unable to open camera\n";
		exit(-1);
	}


	for (;;)
	{
		cap.read(img_frame);
		if (img_frame.empty()) {
			std::cerr << "ERROR! blank frame grabbed\n";
			break;
		}

		//HSV로 변환
		cvtColor(img_frame, img_hsv, COLOR_BGR2HSV);

		//지정한 HSV 범위를 이용하여 영상을 이진화
		Mat img_mask1, img_mask2;

		inRange(img_hsv, Scalar(low_hue1, 50, 10), Scalar(high_hue1, 255, 255), img_mask1);
		if (range_count == 2) {
			inRange(img_hsv, Scalar(low_hue2, 50, 10), Scalar(high_hue2, 255, 255), img_mask2);
			img_mask1 |= img_mask2;
		}

		//morphological opening 작은 점들을 제거 
		erode(img_mask1, img_mask1, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)));
		dilate(img_mask1, img_mask1, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)));

		//morphological closing 영역의 구멍 메우기 
		dilate(img_mask1, img_mask1, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)));
		erode(img_mask1, img_mask1, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)));

		//라벨링 
		Mat img_labels, stats, centroids;
		int numOfLables = connectedComponentsWithStats(img_mask1, img_labels,
			stats, centroids, 8, CV_32S);


		//영역박스 그리기
		int max = -1, idx = 0;
		for (int j = 1; j < numOfLables; j++) {
			int area = stats.at<int>(j, CC_STAT_AREA);
			if (max < area)
			{
				max = area;
				idx = j;
			}
		}
		int left = stats.at<int>(idx, CC_STAT_LEFT);
		int top = stats.at<int>(idx, CC_STAT_TOP);
		int width = stats.at<int>(idx, CC_STAT_WIDTH);
		int height = stats.at<int>(idx, CC_STAT_HEIGHT);

		/*   rectangle(img_frame, Point(left, top), Point(left + width, top + height),
		Scalar(0, 0, 255), 1);*/
	//	cv::imshow("11", img_frame);
		////////////////////////////////////////////////////////////////////////////////////
		Mat smallframe = img_frame(Range(top , top + height), Range(left + 50, left + width ));
		//Mat smallframe = img_frame(Range(top, top + height), Range(left, left + width));
		Mat temp1, temp2;
		cvtColor(smallframe, temp1, COLOR_BGR2HLS_FULL);
		std::vector<Mat> channels(temp1.channels());
		split(temp1, channels);
		equalizeHist(channels[1], channels[1]);
		merge(channels, temp1);
		cvtColor(temp1, temp2, COLOR_HLS2BGR_FULL);
		cvtColor(temp2, temp1, CV_RGB2GRAY);

		int checkstarti = 0;
		int checkfinal = 0;
		int checktemp = 0;
		for (int i = 0; i < temp1.rows; i++) {
			for (int j = 0; j < temp1.cols; j++) {
				if (temp1.at<uchar>(i, j) < 245)
					temp1.at<uchar>(i, j) = 0;
				else {
					checktemp++;
					if (checktemp == 2) {
						checkfinal = i;
						checkstarti = j;
					}
				}
			}
		}

		//imshow("eye_resize", temp1);

	
		

		temp2 = img_frame(Range(top, top + 50 + checkfinal), Range(left + checkstarti, left + 70 + checkstarti));
		cv::resize(temp2, temp1, cv::Size(temp2.cols * 4, temp2.rows * 4), 0, 0, CV_INTER_NN);

		
		///////////////////////////////////////////////////////////////////////////////////////
		cv::Mat gray;
		cv::cvtColor(~temp1, gray, CV_BGR2GRAY);


		Mat gray1;
		cv::threshold(gray, gray1, 220, 255, THRESH_BINARY);


		cv::findContours(gray1, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_NONE);

		//cv::drawContours(gray1, contours, -1, CV_RGB(255, 255, 255), -1);
		//cv::imshow("imag", gray1);


		for (int i = 0; i < contours.size(); i++)
		{
			double area = cv::contourArea(contours[i]);
			cv::Rect rect = cv::boundingRect(contours[i]);
			int radius = rect.width;
			approxPolyDP(Mat(contours[i]), approx, arcLength(Mat(contours[i]), true)*0.02, true);

			// If contour is big enough and has round shape 
			// Then it is the pupil 
			if (fabs(contourArea(Mat(approx))) > 200)
			{
				
				if (rect.x > 30 && rect.y > 110) {
					rectangle(img_frame, Point(left + checkstarti + rect.x / 4, top + rect.y / 4), Point(left + checkstarti + (rect.x + radius) / 4, top + (rect.y + radius) / 4),
						Scalar(0, 0, 255), 1);
					rectangle(temp1, Point(rect.x, rect.y), Point(rect.x + radius, rect.y + radius),
						Scalar(0, 0, 255), 1);
				}

				if (rect.y >= 120 && rect.y < 130) {
					if (t2 == false) {
						if (t1 == false)
							//line(srcimg, Point(80, 50 + srcimgy*srcterm), Point(400, 50 + srcimgy*srcterm), Scalar(255, 0, 0), 2);
						//std::cout << "/----/";
						t1 = true;

					}
					else if (t4 == true) {
						t1 = false, t2 = false, t3 = false, t4 = false;
						srcterm++;
						std::cout << std::endl;
					}

					//std::cout << "d" << std::endl;
				}
				else if (rect.y >= 130 && rect.y < 140) {
					if (t1 == true && t3 == false) {
						if (t2 == false)
							//line(srcimg, Point(400, 50 + srcimgy*srcterm), Point(800, 50 + srcimgy*srcterm), Scalar(255, 0, 0), 2);
						//std::cout << "/----/";
						t2 = true;
					}
					if (t3 == true) {
						if (t4 == false)
							std::cout << "/----/";
						t4 = true;

					}
					//std::cout << "   m" << std::endl;
				}
				else if (rect.y >= 140) {
					if (t1 == true && t2 == true && t4 == false) {
						if (t3 == false)
							//line(srcimg, Point(800, 50 + srcimgy*srcterm), Point(1100, 50 + srcimgy*srcterm), Scalar(255, 0, 0), 2);
						//std::cout << "/----/";
						t3 = true;

					}

					std::cout << "        u" << std::endl;

				}
				//std::cout << t1 << t2 << t3 << t4 << t5 << std::endl;
				std::cout << "                        " << rect.y << std::endl;
				int tempq = rect.y;
				if (tempq < 120)
					tempq = 120;
				if (tempq > 140)
					tempq = 141;
				line(srcimg, Point(80, 50 + srcimgy*srcterm), Point(80+50*(tempq-120), 50 + srcimgy*srcterm), Scalar(255, 0, 0), 2);
			}
		}

		rectangle(img_frame, Point(left + 30 + checkstarti, top + 30 + checkfinal), Point(left + 30 + checkstarti + 30, top + 30 + checkfinal + 20),
			Scalar(0, 0, 255), 1);
		rectangle(img_frame, Point(left, top), Point(left + width, top + height),
			Scalar(0, 255, 255), 1);

		rectangle(img_frame, Point(left + 10+checkstarti, top), Point(left +10+ 30 + checkstarti, top + 30 + checkfinal),
			Scalar(255, 255, 255), 1);

		
		imshow("full_video", img_frame);
		imshow("reading", srcimg);


		if (waitKey(5) >= 0)
			break;
	}

	AfxMessageBox("Completed");
}

